ion 1

What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)

This function should return a float.

def answer_one():

    

    unique_tokens = len(set(nltk.word_tokenize(moby_raw)))

    total_token = len(nltk.word_tokenize(moby_raw))

    

    

    

    return float(unique_tokens)/total_token

?

answer_one()

0.08139566804842562

Question 2

What percentage of tokens is 'whale'or 'Whale'?

This function should return a float.

def answer_two():

    

    dist = FreqDist(nltk.word_tokenize(moby_raw))

    c =  dist['whale'] +dist['Whale']

?

    

    return float(c)*100/len(nltk.word_tokenize(moby_raw))

?

answer_two()

0.4125668166077752

Question 3

What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?

This function should return a list of 20 tuples where each tuple is of the form (token, frequency). The list should be sorted in descending order of frequency.

def answer_three():

    

    tokens = nltk.word_tokenize(moby_raw)

    

    dist = FreqDist(tokens)

    list = []

    

    for w in sorted(dist, key=dist.get, reverse=True):

        tup = (w, dist[w])

        list.append(tup)

        

    print (list[:20])

    

    

    return list[:20]

?

answer_three()

[(',', 19204), ('the', 13715), ('.', 7308), ('of', 6513), ('and', 6010), ('a', 4545), ('to', 4515), (';', 4173), ('in', 3908), ('that', 2978), ('his', 2459), ('it', 2196), ('I', 2097), ('!', 1767), ('is', 1722), ('--', 1713), ('with', 1659), ('he', 1658), ('was', 1639), ('as', 1620)]

[(',', 19204),
 ('the', 13715),
 ('.', 7308),
 ('of', 6513),
 ('and', 6010),
 ('a', 4545),
 ('to', 4515),
 (';', 4173),
 ('in', 3908),
 ('that', 2978),
 ('his', 2459),
 ('it', 2196),
 ('I', 2097),
 ('!', 1767),
 ('is', 1722),
 ('--', 1713),
 ('with', 1659),
 ('he', 1658),
 ('was', 1639),
 ('as', 1620)]

Question 4

What tokens have a length of greater than 5 and frequency of more than 150?

This function should return a sorted list of the tokens that match the above constraints. To sort your list, use sorted()

def answer_four():

    tokens = nltk.word_tokenize(moby_raw)

    dist = FreqDist(tokens)

    list = [w for w in nltk.word_tokenize(moby_raw) if len(w) > 5 and dist[w]>150]

    #print (sorted(set(list)))

    

    return sorted(set(list))

?

answer_four()

['Captain',
 'Pequod',
 'Queequeg',
 'Starbuck',
 'almost',
 'before',
 'himself',
 'little',
 'seemed',
 'should',
 'though',
 'through',
 'whales',
 'without']

Question 5

Find the longest word in text1 and that word's length.

This function should return a tuple (longest_word, length).

def answer_five():

    lst = (list(set(text1)))

    

    print ([w for w in text1 if len(w) > 22 ])

    

    save = ""

    ln = 0

    for x in lst:

        if len(x)>ln:

            save = x

            ln = len(x)

            print (save)

    

    

    return (save,ln)

?

answer_five()

["twelve-o'clock-at-night"]
spurred
lock-jaws
Unicornism
thousand-fold
four-and-twenty
message-carrying
top-gallant-sails
Jonas-in-the-Whale
dentistical-looking
uninterpenetratingly
standers-of-mast-heads
twelve-o'clock-at-night

("twelve-o'clock-at-night", 23)

Question 6

What unique words have a frequency of more than 2000? What is their frequency?

"Hint: you may want to use isalpha() to check if the token is a word and not punctuation."

This function should return a list of tuples of the form (frequency, word) sorted in descending order of frequency.

def answer_six():

    tokens = nltk.word_tokenize(moby_raw)

    dist = FreqDist(tokens)    

    

    lst = []

    

    for w in sorted(dist, key=dist.get, reverse=True):

        if w.isalpha() and dist[w]>2000:

            tup = ( dist[w],w)

            lst.append(tup)

        

    return lst

?

answer_six()

[(13715, 'the'),
 (6513, 'of'),
 (6010, 'and'),
 (4545, 'a'),
 (4515, 'to'),
 (3908, 'in'),
 (2978, 'that'),
 (2459, 'his'),
 (2196, 'it'),
 (2097, 'I')]

Question 7

What is the average number of tokens per sentence?

This function should return a float.

def answer_seven():

    sentences = nltk.sent_tokenize(moby_raw)

    len_sent = len(sentences)

    print (len_sent)

    ln = 0 

    

    for rows in sentences:

        ln = ln+len(nltk.word_tokenize(rows))

        

    print (ln)

    return float(ln)/9852

?

answer_seven()

9852
254989

25.881952902963864

Question 8

What are the 5 most frequent parts of speech in this text? What is their frequency?

This function should return a list of tuples of the form (part_of_speech, frequency) sorted in descending order of frequency.

def answer_eight():

    print ("here")

    mobi_tokens = nltk.word_tokenize(moby_raw)

    mobi_token_arr = []

    for x in mobi_tokens:

        if x.isalpha():

            mobi_token_arr.append(x)

            

    txt = nltk.pos_tag(mobi_token_arr)

    ser = pd.Series()

    for word in txt:

        ser  = ser.append(pd.Series(word[1]))

    

    print (nltk.FreqDist(tag for (word, tag) in txt).most_common(5))

    

    

    dist = FreqDist(txt)

   

    

    

    print (dist[1])

    

    lst = []

    

    #print (sorted(dist, key=dist.get, reverse=True))

            

    

    print (dist.keys())

    

    return list

?

answer_eight()